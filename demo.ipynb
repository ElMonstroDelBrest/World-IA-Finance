{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": "# Financial-IA — Latent Market Intelligence Demo (v4)\n\n**End-to-end demo of the Strate IV PPO agent** operating in latent space learned by Fin-JEPA.\n\nThis notebook:\n1. Installs dependencies and clones the repo\n2. Downloads pre-trained checkpoints (PPO agent + VecNormalize + trajectory buffer)\n3. Runs the agent on held-out evaluation episodes\n4. Visualizes regime switching, position management, and PnL vs Buy & Hold\n\n**No training required** — inference only (~30 seconds on CPU, ~5s on GPU).\n\n---\n> Architecture: Spherical VQ-VAE → Fin-JEPA (Mamba-2) → Stochastic Predictor → PPO Agent  \n> Paper reference: LeCun (2022) *A Path Towards Autonomous Machine Intelligence* — JEPA framework"
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch pytorch-lightning tslearn numpy pandas dacite pyyaml einops gymnasium stable-baselines3 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone the repo (skip if already cloned)\n",
    "if not os.path.exists('World-IA-Finance'):\n",
    "    !git clone https://github.com/ElMonstroDelBrest/World-IA-Finance.git\n",
    "\n",
    "os.chdir('World-IA-Finance')\n",
    "print('Working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download-header",
   "metadata": {},
   "source": [
    "## 2. Download Pre-trained Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download",
   "metadata": {},
   "outputs": [],
   "source": "import urllib.request\nimport zipfile\nfrom pathlib import Path\n\nBASE_URL = \"https://github.com/ElMonstroDelBrest/World-IA-Finance/releases/download/v4.0.0\"\n\ndef download(url, dest):\n    dest = Path(dest)\n    if dest.exists():\n        print(f'  {dest} already exists, skipping.')\n        return\n    dest.parent.mkdir(parents=True, exist_ok=True)\n    print(f'  Downloading {dest.name}...')\n    urllib.request.urlretrieve(url, dest)\n    print(f'  Done ({dest.stat().st_size / 1e6:.1f} MB)')\n\n# PPO model checkpoint (v4, trained with VecNormalize)\nprint('Downloading PPO model...')\ndownload(\n    f\"{BASE_URL}/best_model.zip\",\n    \"checkpoints/strate_iv/best_model.zip\"\n)\n\n# VecNormalize stats (MUST match the model)\nprint('Downloading VecNormalize stats...')\ndownload(\n    f\"{BASE_URL}/vecnormalize.pkl\",\n    \"checkpoints/strate_iv/vecnormalize.pkl\"\n)\n\n# Pre-computed trajectory buffer (JEPA latent representations)\nprint('Downloading trajectory buffer...')\ndownload(\n    f\"{BASE_URL}/trajectory_buffer_v4.zip\",\n    \"/tmp/trajectory_buffer_v4.zip\"\n)\n\n# Extract trajectory buffer\nbuf_dir = Path('data/trajectory_buffer_v4')\nif not buf_dir.exists() or not any(buf_dir.glob('*.pt')):\n    print('Extracting trajectory buffer...')\n    with zipfile.ZipFile('/tmp/trajectory_buffer_v4.zip', 'r') as z:\n        z.extractall('.')\n    print(f'  Extracted {len(list(buf_dir.glob(\"*.pt\")))} episodes')\nelse:\n    print(f'  Buffer already extracted: {len(list(buf_dir.glob(\"*.pt\")))} episodes')\n\nprint('\\nAll assets ready.')"
  },
  {
   "cell_type": "markdown",
   "id": "demo-header",
   "metadata": {},
   "source": "## 3. Run Agent Demo\n\nThe PPO agent operates on **latent observations** — not raw prices. Each step, it receives:\n- The JEPA context encoding of past market regimes\n- A distribution of N=16 stochastic future trajectories (mean & std at current step)\n- Close return statistics, volatility regime, macro trend\n- Its current position and cumulative PnL\n\nIt outputs a continuous action in `[-1, 1]` (short → flat → long).\n\n**v4**: Observations are normalized via VecNormalize (loaded from `vecnormalize.pkl`). The obs_dim is auto-detected from the trajectory buffer."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-demo",
   "metadata": {},
   "outputs": [],
   "source": "import sys, os\nsys.path.insert(0, '.')\n\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')\nfrom pathlib import Path\nfrom IPython.display import display, Image\n\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\nfrom src.strate_iv.config import load_config\nfrom src.strate_iv.env import LatentCryptoEnv\nfrom src.strate_iv.trajectory_buffer import TrajectoryBuffer\nfrom scripts.demo_results import run_episode, plot_demo\n\n# Load config and buffer\nconfig = load_config('configs/strate_iv.yaml')\nbuffer = TrajectoryBuffer('data/trajectory_buffer_v4/')\n_, eval_buffer = buffer.split(val_ratio=config.buffer.val_ratio)\nprint(f'Eval buffer: {len(eval_buffer)} episodes')\n\n# Create env — obs_dim auto-detected from buffer\nenv = LatentCryptoEnv(buffer=eval_buffer, config=config.env)\nobs_dim = env.observation_space.shape[0]\nprint(f'Auto-detected obs_dim: {obs_dim}')\n\n# Load VecNormalize + PPO model\nvecnorm_path = 'checkpoints/strate_iv/vecnormalize.pkl'\nmodel_path = 'checkpoints/strate_iv/best_model.zip'\n\nvec_env = DummyVecEnv([lambda: LatentCryptoEnv(buffer=eval_buffer, config=config.env)])\nvec_env = VecNormalize.load(vecnorm_path, vec_env)\nvec_env.training = False\nvec_env.norm_reward = False\n\nmodel = PPO.load(model_path, env=vec_env)\nprint(f'PPO model loaded — obs dim: {model.observation_space.shape[0]}')\nprint(f'VecNormalize loaded from {vecnorm_path}')\nprint(f'Window: {config.env.n_tgt} patches × {config.env.patch_len} candles = {config.env.n_tgt * config.env.patch_len}h')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-episodes",
   "metadata": {},
   "outputs": [],
   "source": "# Run episodes through the VecNormalize-wrapped env\nPath('outputs/demo').mkdir(parents=True, exist_ok=True)\nn_demos = 5\nresults = []\n\nprint(f'Running {n_demos} episodes...\\n')\nfor i in range(n_demos):\n    traj = run_episode(model, vec_env, seed=None, use_vec=True)\n    out_path = f'outputs/demo/demo_v4_{i:02d}.png'\n    plot_demo(traj, out_path)\n    results.append((out_path, traj))\n    print(f'  Episode {i+1}: actions = {traj[\"actions\"].round(2).tolist()}')"
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-results",
   "metadata": {},
   "outputs": [],
   "source": "from IPython.display import display, Image\n\nfor i, (out_path, traj) in enumerate(results):\n    print(f'\\n--- Episode {i+1} | actions = {traj[\"actions\"].round(2).tolist()} ---')\n    display(Image(filename=out_path, width=900))\n"
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": "## 5. Summary\n\n### What you just saw\n\nThe agent **never sees raw prices** during inference. It operates entirely on latent representations produced by Fin-JEPA:\n\n| Component | Role |\n|---|---|\n| **Spherical VQ-VAE** (Strate I) | Tokenizes OHLCV patches → discrete market regime tokens |\n| **Fin-JEPA + Mamba-2** (Strate II) | Self-supervised temporal model over token sequences |\n| **Stochastic Predictor** (Strate III) | Samples N=16 divergent future latent trajectories |\n| **PPO Agent** (Strate IV) | Plans in latent space, outputs continuous position [-1, 1] |\n\n### v4 improvements\n\n- **VecNormalize**: Observations are normalized (JEPA latents have norms of ~50M). The `vecnormalize.pkl` is always saved alongside the model.\n- **Auto-detected obs_dim**: No hardcoded fallback — obs structure is always derived from the trajectory buffer.\n- **600 episodes**: Larger trajectory buffer for better coverage of market regimes.\n\n### Why this matters\n\nClassical approaches (LSTM, Transformer on raw prices) are forced to predict **every tick** — memorizing noise instead of learning structure.  \nJEPA learns to predict **latent representations** of future states, ignoring unpredictable details.  \nThe agent then plans in this cleaner latent space, exhibiting genuine **regime switching** rather than curve-fitting.\n\n---\n\n**Repository:** https://github.com/ElMonstroDelBrest/World-IA-Finance  \n**License:** AGPL-3.0"
  }
 ]
}