{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Financial-IA — Latent Market Intelligence Demo\n",
    "\n",
    "**End-to-end demo of the Strate IV PPO agent** operating in latent space learned by Fin-JEPA.\n",
    "\n",
    "This notebook:\n",
    "1. Installs dependencies and clones the repo\n",
    "2. Downloads pre-trained checkpoints (PPO agent + trajectory buffer)\n",
    "3. Runs the agent on held-out evaluation episodes\n",
    "4. Visualizes regime switching, position management, and PnL vs Buy & Hold\n",
    "\n",
    "**No training required** — inference only (~30 seconds on CPU, ~5s on GPU).\n",
    "\n",
    "---\n",
    "> Architecture: Spherical VQ-VAE → Fin-JEPA (Mamba-2) → Stochastic Predictor → PPO Agent  \n",
    "> Paper reference: LeCun (2022) *A Path Towards Autonomous Machine Intelligence* — JEPA framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch pytorch-lightning tslearn numpy pandas dacite pyyaml einops gymnasium stable-baselines3 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone the repo (skip if already cloned)\n",
    "if not os.path.exists('World-IA-Finance'):\n",
    "    !git clone https://github.com/ElMonstroDelBrest/World-IA-Finance.git\n",
    "\n",
    "os.chdir('World-IA-Finance')\n",
    "print('Working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download-header",
   "metadata": {},
   "source": [
    "## 2. Download Pre-trained Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download",
   "metadata": {},
   "outputs": [],
   "source": "import urllib.request\nimport zipfile\nfrom pathlib import Path\n\nBASE_URL = \"https://github.com/ElMonstroDelBrest/World-IA-Finance/releases/download/v1.0.0\"\n\ndef download(url, dest):\n    dest = Path(dest)\n    if dest.exists():\n        print(f'  {dest} already exists, skipping.')\n        return\n    dest.parent.mkdir(parents=True, exist_ok=True)\n    print(f'  Downloading {dest.name}...')\n    urllib.request.urlretrieve(url, dest)\n    print(f'  Done ({dest.stat().st_size / 1e6:.1f} MB)')\n\n# PPO model checkpoint (trained without VecNormalize, 415 obs dim)\nprint('Downloading PPO model...')\ndownload(\n    f\"{BASE_URL}/ppo_strate_iv_final.zip\",\n    \"checkpoints/strate_iv/ppo_strate_iv_final.zip\"\n)\n\n# Pre-computed trajectory buffer (JEPA latent representations)\nprint('Downloading trajectory buffer...')\ndownload(\n    f\"{BASE_URL}/trajectory_buffer.zip\",\n    \"/tmp/trajectory_buffer.zip\"\n)\n\n# Extract trajectory buffer\nbuf_dir = Path('data/trajectory_buffer')\nif not buf_dir.exists() or not any(buf_dir.glob('*.pt')):\n    print('Extracting trajectory buffer...')\n    with zipfile.ZipFile('/tmp/trajectory_buffer.zip', 'r') as z:\n        z.extractall('.')\n    print(f'  Extracted {len(list(buf_dir.glob(\"*.pt\")))} episodes')\nelse:\n    print(f'  Buffer already extracted: {len(list(buf_dir.glob(\"*.pt\")))} episodes')\n\nprint('\\nAll assets ready.')\n"
  },
  {
   "cell_type": "markdown",
   "id": "demo-header",
   "metadata": {},
   "source": [
    "## 3. Run Agent Demo\n",
    "\n",
    "The PPO agent operates on **latent observations** — not raw prices. Each step, it receives:\n",
    "- The JEPA context encoding of past market regimes\n",
    "- A distribution of N=16 stochastic future trajectories\n",
    "- Its current position and cumulative PnL\n",
    "\n",
    "It outputs a continuous action in `[-1, 1]` (short → flat → long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-demo",
   "metadata": {},
   "outputs": [],
   "source": "import sys, os\nsys.path.insert(0, '.')\n\nimport numpy as np\nimport types\nimport gymnasium as gym\nimport matplotlib\nmatplotlib.use('Agg')\nfrom pathlib import Path\nfrom IPython.display import display, Image\n\nfrom stable_baselines3 import PPO\nfrom src.strate_iv.config import load_config\nfrom src.strate_iv.env import LatentCryptoEnv\nfrom src.strate_iv.trajectory_buffer import TrajectoryBuffer\nfrom scripts.demo_results import run_episode, plot_demo\n\nEPS = 1e-8\n\n# Load config and buffer\nconfig = load_config('configs/strate_iv.yaml')\nbuffer = TrajectoryBuffer('data/trajectory_buffer/')\n_, eval_buffer = buffer.split(val_ratio=config.buffer.val_ratio)\nprint(f'Eval buffer: {len(eval_buffer)} episodes')\n\n# Load PPO model (415 obs dim, no VecNormalize)\nmodel_path = 'checkpoints/strate_iv/ppo_strate_iv_final.zip'\nmodel = PPO.load(model_path)\nprint(f'PPO model loaded — obs dim: {model.observation_space.shape[0]}')\n\n# Patch env to use original 415-dim obs (no delta_mu, no step_progress, no realized_returns)\ndef _build_obs_v1(self, entry, step_idx=0, realized_idx=0, position=0.0, cum_pnl=0.0):\n    future_latents = entry.future_latents.numpy()\n    h_x_pooled    = entry.h_x_pooled.numpy()\n    future_mean   = future_latents.mean(axis=0).mean(axis=0)\n    future_std    = future_latents.std(axis=0).mean(axis=0)\n    close_stats   = self._compute_close_stats(entry.future_ohlcv.numpy())\n    revin_stds    = entry.revin_stds.numpy().flatten()\n    pos           = np.array([position],  dtype=np.float32)\n    cpnl          = np.array([cum_pnl],   dtype=np.float32)\n    obs = np.concatenate([\n        h_x_pooled, future_mean, future_std,\n        close_stats, revin_stds, pos, cpnl,\n    ]).astype(np.float32)\n    return np.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)\n\nenv = LatentCryptoEnv(buffer=eval_buffer, config=config.env)\nenv._build_observation_from = types.MethodType(_build_obs_v1, env)\nenv.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(415,), dtype=np.float32)\n\nobs_test = env._build_observation_from(eval_buffer.entries[0])\nprint(f'Obs dim: {obs_test.shape[0]}')\nprint(f'Window: {config.env.n_tgt} patches × {config.env.patch_len} candles = {config.env.n_tgt * config.env.patch_len}h')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-episodes",
   "metadata": {},
   "outputs": [],
   "source": "# Run episodes using scripts/demo_results.py logic (no VecNormalize needed)\nPath('outputs/demo').mkdir(parents=True, exist_ok=True)\nn_demos = 5\nresults = []\n\nprint(f'Running {n_demos} episodes...\\n')\nfor i in range(n_demos):\n    traj = run_episode(model, env, seed=None)\n    out_path = f'outputs/demo/demo_{i:02d}.png'\n    plot_demo(traj, out_path)\n    results.append((out_path, traj))\n    print(f'  Episode {i+1}: actions = {traj[\"actions\"].round(2).tolist()}')\n"
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-results",
   "metadata": {},
   "outputs": [],
   "source": "from IPython.display import display, Image\n\nfor i, (out_path, traj) in enumerate(results):\n    print(f'\\n--- Episode {i+1} | actions = {traj[\"actions\"].round(2).tolist()} ---')\n    display(Image(filename=out_path, width=900))\n"
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "### What you just saw\n",
    "\n",
    "The agent **never sees raw prices** during inference. It operates entirely on latent representations produced by Fin-JEPA:\n",
    "\n",
    "| Component | Role |\n",
    "|---|---|\n",
    "| **Spherical VQ-VAE** (Strate I) | Tokenizes OHLCV patches → discrete market regime tokens |\n",
    "| **Fin-JEPA + Mamba-2** (Strate II) | Self-supervised temporal model over token sequences |\n",
    "| **Stochastic Predictor** (Strate III) | Samples N=16 divergent future latent trajectories |\n",
    "| **PPO Agent** (Strate IV) | Plans in latent space, outputs continuous position [-1, 1] |\n",
    "\n",
    "### Why this matters\n",
    "\n",
    "Classical approaches (LSTM, Transformer on raw prices) are forced to predict **every tick** — memorizing noise instead of learning structure.  \n",
    "JEPA learns to predict **latent representations** of future states, ignoring unpredictable details.  \n",
    "The agent then plans in this cleaner latent space, exhibiting genuine **regime switching** rather than curve-fitting.\n",
    "\n",
    "---\n",
    "\n",
    "**Repository:** https://github.com/ElMonstroDelBrest/World-IA-Finance  \n",
    "**License:** AGPL-3.0"
   ]
  }
 ]
}